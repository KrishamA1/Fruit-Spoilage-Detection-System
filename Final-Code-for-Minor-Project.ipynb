{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4024721",
   "metadata": {},
   "source": [
    "# Fruit Rottenness Detection Using CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b868a7",
   "metadata": {},
   "source": [
    "## Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5564ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T15:04:47.690047Z",
     "iopub.status.busy": "2024-01-12T15:04:47.689581Z",
     "iopub.status.idle": "2024-01-12T15:05:06.889284Z",
     "shell.execute_reply": "2024-01-12T15:05:06.887845Z",
     "shell.execute_reply.started": "2024-01-12T15:04:47.690006Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.utils import Sequence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fec70e",
   "metadata": {},
   "source": [
    "## Setting the path to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635f5c25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T15:05:06.892311Z",
     "iopub.status.busy": "2024-01-12T15:05:06.891505Z",
     "iopub.status.idle": "2024-01-12T15:05:06.898255Z",
     "shell.execute_reply": "2024-01-12T15:05:06.897222Z",
     "shell.execute_reply.started": "2024-01-12T15:05:06.892269Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set the path to your dataset\n",
    "train_data_dir = 'dataset/training_set'\n",
    "test_data_dir = 'dataset/test_set'\n",
    "img_width, img_height = 40, 40\n",
    "batch_size = 60\n",
    "epochs = 15\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc529e9c",
   "metadata": {},
   "source": [
    "## Defining functions for Preprocessing Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcd5b5b",
   "metadata": {},
   "source": [
    "### Segmentation (K-Means Clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f482849d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T15:05:06.900220Z",
     "iopub.status.busy": "2024-01-12T15:05:06.899610Z",
     "iopub.status.idle": "2024-01-12T15:05:06.948430Z",
     "shell.execute_reply": "2024-01-12T15:05:06.947093Z",
     "shell.execute_reply.started": "2024-01-12T15:05:06.900184Z"
    }
   },
   "outputs": [],
   "source": [
    "def custom_preprocessing(image, k=4, max_iterations=100, epsilon=0.2):\n",
    "    # Reshape the image to a 2D array of pixels\n",
    "    pixels = image.reshape((-1, 3))\n",
    "\n",
    "    # Convert pixels to float32\n",
    "    pixels = pixels.astype(np.float32)\n",
    "\n",
    "    # Initialize k centroids randomly\n",
    "    centroids = pixels[np.random.choice(pixels.shape[0], k, replace=False)]\n",
    "\n",
    "    for _ in range(max_iterations):\n",
    "        # Calculate distances between each pixel and centroids\n",
    "        distances = np.linalg.norm(pixels[:, np.newaxis, :] - centroids, axis=2)\n",
    "\n",
    "        # Assign each pixel to the closest centroid\n",
    "        labels = np.argmin(distances, axis=1)\n",
    "\n",
    "        # Update centroids based on the mean of pixels in each cluster\n",
    "        for i in range(k):\n",
    "            cluster_pixels = pixels[labels == i]\n",
    "            if len(cluster_pixels) > 0:\n",
    "                centroids[i] = np.mean(cluster_pixels, axis=0)\n",
    "\n",
    "    # Assign each pixel to the final centroids\n",
    "    segmented_image = centroids[labels]\n",
    "    \n",
    "    # Reshape the segmented image to the original shape\n",
    "    segmented_image = segmented_image.reshape(image.shape)\n",
    "\n",
    "    return segmented_image.astype('float32')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec237a8",
   "metadata": {},
   "source": [
    "### Grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156e05fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T15:05:06.952866Z",
     "iopub.status.busy": "2024-01-12T15:05:06.952357Z",
     "iopub.status.idle": "2024-01-12T15:05:06.964728Z",
     "shell.execute_reply": "2024-01-12T15:05:06.963236Z",
     "shell.execute_reply.started": "2024-01-12T15:05:06.952819Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating Grayscale Version of the Image\n",
    "def custom_preprocessing2(image):\n",
    "    # Extract the RGB channels\n",
    "    red_channel = image[:, :, 0]\n",
    "    green_channel = image[:, :, 1]\n",
    "    blue_channel = image[:, :, 2]\n",
    "\n",
    "    # Convert to grayscale using the formula: grayscale = 0.299 * R + 0.587 * G + 0.114 * B\n",
    "    grayscale_image = 0.299 * red_channel + 0.587 * green_channel + 0.114 * blue_channel\n",
    "\n",
    "    # Expand dimensions to make it compatible with the model's input shape\n",
    "    grayscale_image = np.expand_dims(grayscale_image, axis=-1)\n",
    "\n",
    "    return grayscale_image.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad52284",
   "metadata": {},
   "source": [
    "### Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967a4f0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T15:05:06.967035Z",
     "iopub.status.busy": "2024-01-12T15:05:06.966452Z",
     "iopub.status.idle": "2024-01-12T15:05:06.977389Z",
     "shell.execute_reply": "2024-01-12T15:05:06.975960Z",
     "shell.execute_reply.started": "2024-01-12T15:05:06.966999Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def custom_preprocessing3(image):\n",
    "    # Convert the image to grayscale\n",
    "    grayscale_image = rgb2gray(image)\n",
    "\n",
    "    # Define Sobel kernels for horizontal and vertical edge detection\n",
    "    kernel_x = np.array([[-1, 0, 1],\n",
    "                        [-2, 0, 2],\n",
    "                        [-1, 0, 1]])\n",
    "\n",
    "    kernel_y = np.array([[-1, -2, -1],\n",
    "                        [0, 0, 0],\n",
    "                        [1, 2, 1]])\n",
    "\n",
    "    # Apply convolution with the Sobel kernels\n",
    "    sobel_x = convolve2d(grayscale_image, kernel_x, mode='same', boundary='symm')\n",
    "    sobel_y = convolve2d(grayscale_image, kernel_y, mode='same', boundary='symm')\n",
    "\n",
    "    # Calculate the gradient magnitude\n",
    "    gradient_magnitude = np.sqrt(sobel_x**2 + sobel_y**2)\n",
    "\n",
    "    # Normalize the gradient magnitude to the range [0, 255]\n",
    "    normalized_gradient = (gradient_magnitude / gradient_magnitude.max()) * 255\n",
    "\n",
    "    # Convert to uint8 type\n",
    "    edges = normalized_gradient.astype(np.uint8)\n",
    "\n",
    "    # Expand dimensions to make it compatible with the model's input shape\n",
    "    edges = np.expand_dims(edges, axis=-1)\n",
    "\n",
    "    return edges.astype('float32')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e22ad0",
   "metadata": {},
   "source": [
    "### Noise Addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ffc3e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T15:05:06.982054Z",
     "iopub.status.busy": "2024-01-12T15:05:06.981033Z",
     "iopub.status.idle": "2024-01-12T15:05:06.990159Z",
     "shell.execute_reply": "2024-01-12T15:05:06.988748Z",
     "shell.execute_reply.started": "2024-01-12T15:05:06.982004Z"
    }
   },
   "outputs": [],
   "source": [
    "def custom_preprocessing4(image, noise_intensity=75):\n",
    "    # Convert the image to a NumPy array\n",
    "    image_array = np.array(image)\n",
    "\n",
    "    # Get the shape of the image\n",
    "    height, width, channels = image_array.shape\n",
    "\n",
    "    # Generate random noise manually\n",
    "    noise = np.random.randint(-noise_intensity, noise_intensity, (height, width, channels))\n",
    "\n",
    "    # Add noise to the original image and clip to [0, 255]\n",
    "    noisy_image = np.clip(image_array + noise, 0, 255).astype('uint8')\n",
    "\n",
    "    return noisy_image.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05b1347",
   "metadata": {},
   "source": [
    "### Shading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096e1ebe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T15:05:06.992206Z",
     "iopub.status.busy": "2024-01-12T15:05:06.991572Z",
     "iopub.status.idle": "2024-01-12T15:05:07.008854Z",
     "shell.execute_reply": "2024-01-12T15:05:07.007835Z",
     "shell.execute_reply.started": "2024-01-12T15:05:06.992171Z"
    }
   },
   "outputs": [],
   "source": [
    "#Applying Shading\n",
    "def custom_preprocessing5(image):\n",
    "    gamma=3\n",
    "    shaded_image = np.clip(np.power(image / 255.0, gamma) * 255.0, 0, 255).astype('uint8')\n",
    "    \n",
    "    return shaded_image.astype('float32')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac29bf79",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1466d86e",
   "metadata": {},
   "source": [
    "### Creating different generators representing each of the preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0e8af2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T15:05:07.010855Z",
     "iopub.status.busy": "2024-01-12T15:05:07.010286Z",
     "iopub.status.idle": "2024-01-12T15:05:15.673441Z",
     "shell.execute_reply": "2024-01-12T15:05:15.672429Z",
     "shell.execute_reply.started": "2024-01-12T15:05:07.010821Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Data Preprocessing\n",
    "train_datagen1 = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "#     vertical_flip=True,\n",
    "    preprocessing_function=custom_preprocessing\n",
    ")\n",
    "\n",
    "# DirectoryIterator for the dataset\n",
    "train_generator1 = train_datagen1.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e68928",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T15:05:15.675597Z",
     "iopub.status.busy": "2024-01-12T15:05:15.674978Z",
     "iopub.status.idle": "2024-01-12T15:05:19.856184Z",
     "shell.execute_reply": "2024-01-12T15:05:19.854608Z",
     "shell.execute_reply.started": "2024-01-12T15:05:15.675563Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "train_datagen2 = ImageDataGenerator(\n",
    "     rescale=1.0 / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "#     vertical_flip=True,\n",
    "    preprocessing_function=custom_preprocessing2\n",
    ")\n",
    "\n",
    "train_generator2 = train_datagen2.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dde44ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T15:05:19.861444Z",
     "iopub.status.busy": "2024-01-12T15:05:19.861012Z",
     "iopub.status.idle": "2024-01-12T15:05:20.679235Z",
     "shell.execute_reply": "2024-01-12T15:05:20.677372Z",
     "shell.execute_reply.started": "2024-01-12T15:05:19.861409Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "train_datagen3 = ImageDataGenerator(\n",
    "     rescale=1.0 / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "#     vertical_flip=True,    \n",
    "    preprocessing_function=custom_preprocessing3\n",
    ")\n",
    "\n",
    "train_generator3 = train_datagen3.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf8b97a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T15:05:20.680950Z",
     "iopub.status.busy": "2024-01-12T15:05:20.680555Z",
     "iopub.status.idle": "2024-01-12T15:05:21.524472Z",
     "shell.execute_reply": "2024-01-12T15:05:21.523131Z",
     "shell.execute_reply.started": "2024-01-12T15:05:20.680919Z"
    }
   },
   "outputs": [],
   "source": [
    "train_datagen4 = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "#     vertical_flip=True,    \n",
    "    preprocessing_function=custom_preprocessing4\n",
    ")\n",
    "\n",
    "train_generator4 = train_datagen4.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6274f81c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T15:05:21.526710Z",
     "iopub.status.busy": "2024-01-12T15:05:21.526262Z",
     "iopub.status.idle": "2024-01-12T15:05:22.341127Z",
     "shell.execute_reply": "2024-01-12T15:05:22.340140Z",
     "shell.execute_reply.started": "2024-01-12T15:05:21.526672Z"
    }
   },
   "outputs": [],
   "source": [
    "train_datagen5 = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "#     vertical_flip=True,    \n",
    "    preprocessing_function=custom_preprocessing5\n",
    ")\n",
    "\n",
    "train_generator5 = train_datagen5.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e30003",
   "metadata": {},
   "source": [
    "### Creating the test generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef34660",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T15:05:22.354466Z",
     "iopub.status.busy": "2024-01-12T15:05:22.354071Z",
     "iopub.status.idle": "2024-01-12T15:05:24.638458Z",
     "shell.execute_reply": "2024-01-12T15:05:24.637108Z",
     "shell.execute_reply.started": "2024-01-12T15:05:22.354433Z"
    }
   },
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1.0/255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(test_data_dir,\n",
    "                                                  target_size=(img_width, img_height),\n",
    "                                                  batch_size=batch_size,\n",
    "                                                  class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e000c42",
   "metadata": {},
   "source": [
    "## Concatenation of all the Generators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac44b5c6",
   "metadata": {},
   "source": [
    "### Creating the class for combining all the generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b88b125",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T15:05:24.643424Z",
     "iopub.status.busy": "2024-01-12T15:05:24.642063Z",
     "iopub.status.idle": "2024-01-12T15:05:24.655725Z",
     "shell.execute_reply": "2024-01-12T15:05:24.653763Z",
     "shell.execute_reply.started": "2024-01-12T15:05:24.643370Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class ConcatenateGenerators(Sequence):\n",
    "    def __init__(self, generators):\n",
    "        self.generators = generators\n",
    "        self.lengths = [len(gen) for gen in generators]\n",
    "        self.cumulative_lengths = np.cumsum(self.lengths)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.cumulative_lengths[-1]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "    # Initialize empty lists to store data and labels from all generators\n",
    "        all_data, all_labels = [], []\n",
    "\n",
    "        for generator_index, generator in enumerate(self.generators):\n",
    "            if index < self.cumulative_lengths[generator_index]:\n",
    "                # Calculate the sample index within the current generator\n",
    "                sample_index = index if generator_index == 0 else index - self.cumulative_lengths[generator_index - 1]\n",
    "\n",
    "                # Get the data and labels from the current generator\n",
    "                data, labels = generator[sample_index]\n",
    "\n",
    "                # Append data and labels to the lists\n",
    "                all_data.append(data)\n",
    "                all_labels.append(labels)\n",
    "\n",
    "        # Concatenate data and labels from all generators\n",
    "        data = np.concatenate(all_data, axis=0)\n",
    "        labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "        return data, labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21e3003",
   "metadata": {},
   "source": [
    "### Combination of multiple generators into a single generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70ece31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T15:05:24.659824Z",
     "iopub.status.busy": "2024-01-12T15:05:24.659247Z",
     "iopub.status.idle": "2024-01-12T15:05:24.694522Z",
     "shell.execute_reply": "2024-01-12T15:05:24.693018Z",
     "shell.execute_reply.started": "2024-01-12T15:05:24.659773Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "combined_generator = ConcatenateGenerators([train_generator1, train_generator2, train_generator3, train_generator4, train_generator5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22af3028",
   "metadata": {},
   "source": [
    "## Building the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4c0d6a",
   "metadata": {},
   "source": [
    "### Defining the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d651f8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T15:05:24.697466Z",
     "iopub.status.busy": "2024-01-12T15:05:24.695953Z",
     "iopub.status.idle": "2024-01-12T15:05:25.057336Z",
     "shell.execute_reply": "2024-01-12T15:05:25.055790Z",
     "shell.execute_reply.started": "2024-01-12T15:05:24.697395Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Initialising the CNN\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "# Step 1 - Convolution\n",
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[40, 40, 3]))\n",
    "# model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "# Step 2 - Pooling\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "# model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "# Adding a second convolutional layer\n",
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "# model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "# Step 3 - Flattening\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "# model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "# Step 4 - Full Connection\n",
    "model.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.1))\n",
    "# model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "\n",
    "# Step 5 - Output Layer\n",
    "model.add(tf.keras.layers.Dense(units=8, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae23179",
   "metadata": {},
   "source": [
    "### Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8df3a65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T15:05:25.059500Z",
     "iopub.status.busy": "2024-01-12T15:05:25.059028Z",
     "iopub.status.idle": "2024-01-12T15:05:25.090680Z",
     "shell.execute_reply": "2024-01-12T15:05:25.089293Z",
     "shell.execute_reply.started": "2024-01-12T15:05:25.059463Z"
    }
   },
   "outputs": [],
   "source": [
    "# lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "#                 initial_learning_rate = 1e-3,\n",
    "#                 decay_steps = 10000,\n",
    "#                 decay_rate = 0.9)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d154d40",
   "metadata": {},
   "source": [
    "### Training the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e85ea1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T15:05:25.093618Z",
     "iopub.status.busy": "2024-01-12T15:05:25.092820Z",
     "iopub.status.idle": "2024-01-12T18:12:58.425757Z",
     "shell.execute_reply": "2024-01-12T18:12:58.424238Z",
     "shell.execute_reply.started": "2024-01-12T15:05:25.093576Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "history = model.fit(combined_generator, epochs=epochs, validation_data=test_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caff922f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T18:12:58.428433Z",
     "iopub.status.busy": "2024-01-12T18:12:58.428031Z",
     "iopub.status.idle": "2024-01-12T18:12:58.469520Z",
     "shell.execute_reply": "2024-01-12T18:12:58.468172Z",
     "shell.execute_reply.started": "2024-01-12T18:12:58.428399Z"
    }
   },
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "train_accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "table_data = [(epoch + 1, train_acc,f\"{train_acc * 100:.2f}%\", val_acc, f\"{val_acc * 100:.2f}%\") for epoch, (train_acc, val_acc) in enumerate(zip(train_accuracy, val_accuracy))]\n",
    "\n",
    "headers = ['Epoch', 'Train Accuracy', 'Train Accuracy (%)', 'Validation Accuracy', 'Validation Accuracy (%)']\n",
    "\n",
    "print(tabulate(table_data, headers=headers, tablefmt='grid'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3923425e",
   "metadata": {},
   "source": [
    "## Plotting the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afc2454",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-12T18:12:58.472375Z",
     "iopub.status.busy": "2024-01-12T18:12:58.471399Z",
     "iopub.status.idle": "2024-01-12T18:12:59.385084Z",
     "shell.execute_reply": "2024-01-12T18:12:59.383817Z",
     "shell.execute_reply.started": "2024-01-12T18:12:58.472335Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "model.save('fruit_classifier_model101.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e89434",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-12T18:13:00.756437Z",
     "iopub.status.idle": "2024-01-12T18:13:00.756953Z",
     "shell.execute_reply": "2024-01-12T18:13:00.756716Z",
     "shell.execute_reply.started": "2024-01-12T18:13:00.756694Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import load_model\n",
    "import cv2\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the pre-trained model\n",
    "model_path = 'fruit_classifier_model.h5'\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Set the path to your test dataset\n",
    "test_data_dir = 'dataset/test_set'\n",
    "img_width, img_height = 35, 35\n",
    "batch_size = 32\n",
    "\n",
    "# Data Preprocessing for testing set\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(test_data_dir,\n",
    "                                                  target_size=(img_width, img_height),\n",
    "                                                  batch_size=batch_size,\n",
    "                                                  class_mode='categorical',\n",
    "                                                  shuffle=False)  # Ensure labels are in the same order as predictions\n",
    "\n",
    "# Get true labels\n",
    "true_labels = test_generator.classes\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(test_generator)\n",
    "\n",
    "# Get predicted labels\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "\n",
    "# Calculate Confusion Matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Display F1 score\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Display Confusion Matrix with rotated x-axis labels\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=test_generator.class_indices, yticklabels=test_generator.class_indices, cbar=True)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.xticks(rotation=45, ha=\"right\")  # Rotate x-axis labels\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c451e72e",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-12T18:13:00.758801Z",
     "iopub.status.idle": "2024-01-12T18:13:00.759378Z",
     "shell.execute_reply": "2024-01-12T18:13:00.759151Z",
     "shell.execute_reply.started": "2024-01-12T18:13:00.759121Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the pretrained model\n",
    "model_path = 'fruit_classifier_model1.h5'\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Function to predict the class of an image\n",
    "def predict_image(image_path):\n",
    "    img = load_img(image_path, target_size=(35, 35))\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
    "\n",
    "    predictions = model.predict(img_array)\n",
    "    classes = {0: 'fresh_apple', 1: 'fresh_banana', 2: 'fresh_orange', 3: 'fresh_strawberry', 4: 'rotten_apple', 5: 'rotten_banana', 6: 'rotten_orange', 7: 'rotten_strawberry'}\n",
    "\n",
    "    # Normalize the probabilities to ensure the sum is 100%\n",
    "    normalized_probabilities = predictions[0] / np.sum(predictions[0])\n",
    "\n",
    "    # Print class probabilities\n",
    "    for i in range(len(normalized_probabilities)):\n",
    "        print(f\"{classes[i]}: {normalized_probabilities[i] * 100:.7f} %\")\n",
    "\n",
    "    # Get the predicted class using the normalized probabilities\n",
    "    predicted_class_index = np.argmax(normalized_probabilities)\n",
    "    predicted_class = classes[predicted_class_index]\n",
    "\n",
    "    print(f\"Predicted class: {predicted_class}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    image_path = 'dataset2/single_prediction/fruit_test_1.jpg'\n",
    "    predict_image(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f1514f",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-01-12T18:13:00.761013Z",
     "iopub.status.idle": "2024-01-12T18:13:00.761572Z",
     "shell.execute_reply": "2024-01-12T18:13:00.761314Z",
     "shell.execute_reply.started": "2024-01-12T18:13:00.761286Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the pretrained model\n",
    "model_path = 'fruit_classifier_model1.h5'\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Function to predict the class of an image\n",
    "def predict_image(image_path):\n",
    "    img = load_img(image_path, target_size=(35, 35))\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
    "\n",
    "    predictions = model.predict(img_array)\n",
    "    classes = {0: 'fresh_apple', 1: 'fresh_banana', 2: 'fresh_orange', 3: 'fresh_strawberry', 4: 'rotten_apple', 5: 'rotten_banana', 6: 'rotten_orange', 7: 'rotten_strawberry'}\n",
    "\n",
    "    # Normalize the probabilities to ensure the sum is 100%\n",
    "    normalized_probabilities = predictions[0] / np.sum(predictions[0])\n",
    "\n",
    "    # Plotting the bar diagram with rotated x-axis labels\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(classes.values(), normalized_probabilities, color=['green' if p >= 0.5 else 'red' for p in normalized_probabilities])\n",
    "    plt.title('Class Probabilities')\n",
    "    plt.xlabel('Classes')\n",
    "    plt.ylabel('Probability')\n",
    "    plt.ylim(0, 1)  # Set the y-axis limit to be between 0 and 1 for probabilities\n",
    "    plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability\n",
    "    plt.tight_layout()  # Adjust layout for better spacing\n",
    "    plt.show()\n",
    "\n",
    "    # Get the predicted class using the normalized probabilities\n",
    "    predicted_class_index = np.argmax(normalized_probabilities)\n",
    "    predicted_class = classes[predicted_class_index]\n",
    "\n",
    "    print(f\"\\nPredicted class: {predicted_class}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    image_path = 'dataset2/single_prediction/rotten_apple_test1.jpg'\n",
    "    predict_image(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ca18f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "model_path = 'fruit_classifier_model1.h5'\n",
    "model = load_model(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9a28fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc407ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4259287,
     "sourceId": 7336658,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30635,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
